"""
Module Name: generic_conversation_agent.py

Description:
This module provides functionality for a generic conversation agent that leverages 
Bing search tools to enhance its responses. It defines the conversation pipeline, 
including loading system prompts, initializing search tools, and handling user input 
to produce AI-driven responses. The module also includes utility functions for token 
counting and input text extraction.

"""

# -----------------------------------------------------------------------------
# SECTION: Imports
# -----------------------------------------------------------------------------

# Standard library imports
from typing import Union, Dict, List
import os

# Third-party imports
from dotenv import load_dotenv
from langchain.agents import AgentExecutor, create_openai_tools_agent, load_tools
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
import tiktoken

# Local application imports
from models.openai.azure_openai_model import llm_config_loader
from utils.helper_functions import load_prompt,load_prompt_yaml

# -----------------------------------------------------------------------------
# SECTION: Load Environment Variables
# -----------------------------------------------------------------------------

# Load environment variables from .env file
load_dotenv()

# Bing API credentials
BING_SUBSCRIPTION_KEY = os.getenv("BING_SUBSCRIPTION_KEY")
BING_SEARCH_ENDPOINT = os.getenv("BING_SEARCH_URL")

# -----------------------------------------------------------------------------
# SECTION: Load Prompts and Tools
# -----------------------------------------------------------------------------

# Load the system generic_conversation prompt from a file
generic_conversation_system_text = load_prompt_yaml(r"config_files\non_core_engine\generic_conversation_prompts\system_prompt.yaml")
generic_conversation_start_text = load_prompt_yaml(r"config_files\non_core_engine\generic_conversation_prompts\start_prompt.yaml")
# Create chat prompt template
generic_conversation_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", generic_conversation_system_text),
        ("user", generic_conversation_start_text),
        MessagesPlaceholder(variable_name="agent_scratchpad")
    ]
)

# Load search tools and create agent
search_tools = load_tools(
    ["bing-search"],
    bing_subscription_key=BING_SUBSCRIPTION_KEY,
    bing_search_url=BING_SEARCH_ENDPOINT
)

llm_with_tools = llm_config_loader().bind_tools(tools=search_tools)
generic_conversation_agent = create_openai_tools_agent(
    llm_with_tools,
    search_tools,
    generic_conversation_prompt
)

agent_executor = AgentExecutor(agent=generic_conversation_agent, tools=search_tools)

# -----------------------------------------------------------------------------
# SECTION: Utility Functions
# -----------------------------------------------------------------------------

def num_tokens_from_string(string: str, encoding_name: str) -> int:
    """
    Calculate the number of tokens in a string based on the specified encoding.

    Args:
        string (str): The input string to encode.
        encoding_name (str): The name of the encoding to use.

    Returns:
        int: The number of tokens in the encoded string.
    """
    encoding = tiktoken.get_encoding(encoding_name)
    return len(encoding.encode(string))


def get_input_text(function_params: Union[Dict[str, str], List[str]]) -> str:
    """
    Extract input text from function parameters.

    Args:
        function_params (Union[Dict[str, str], List[str]]): Either a dictionary with 
        an 'input_text' key or a list with input text.

    Returns:
        str: Extracted input text.

    Raises:
        ValueError: If invalid arguments are passed.
    """
    if isinstance(function_params, dict):
        return function_params.get('user_input', '')
    elif isinstance(function_params, list) and function_params:
        return function_params[0]
    elif isinstance(function_params, str) and function_params:
        return function_params
    raise ValueError("Invalid arguments passed to the generic_conversation_agent function.")

# -----------------------------------------------------------------------------
# SECTION: Main Function
# -----------------------------------------------------------------------------

def generic_conversation_agent(function_params: Union[Dict[str, str], List[str]]) -> tuple:
    """
    Function for the generic conversation agent.

    Args:
        function_params (Union[Dict[str, str], List[str]]): Either a dictionary with 
        an 'input_text' key or a list with input text.

    Returns:
        tuple: A tuple containing:
            - str: Response generated by the generic conversation agent.
            - int: Number of input tokens used.
            - int: Number of output tokens generated.

    Raises:
        ValueError: If invalid arguments are passed to the function.
    """
    input_text = get_input_text(function_params)
    ai_response = agent_executor.invoke({"user_input": input_text})
    
    prompt_as_string = generic_conversation_prompt.format(
        user_input=input_text,
        agent_scratchpad=[]
    )
    
    input_tokens_count = num_tokens_from_string(prompt_as_string, "cl100k_base")
    output_tokens_count = num_tokens_from_string(ai_response['output'], "cl100k_base")
    
    return ai_response['output'], input_tokens_count, output_tokens_count

# -----------------------------------------------------------------------------
# END OF MODULE
# -----------------------------------------------------------------------------