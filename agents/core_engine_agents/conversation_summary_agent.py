"""
Module Name: conversation_summary_agent.py
 
Description:
This module contains the implementation of a Conversation Summary Agent using LangChain components.
If the conversation history exceeds a certain length, this agent summarizes it.
"""
 
# -----------------------------------------------------------------------------
# SECTION: Imports
# -----------------------------------------------------------------------------
 
# Standard library imports
from typing import Union, Dict, List, Tuple
 
# Third-party imports
from langchain_community.callbacks import get_openai_callback
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field
 
# Local application imports
from models.openai.azure_openai_model import llm_config_loader
from utils.helper_functions import load_prompt_yaml
 
# -----------------------------------------------------------------------------
# SECTION: Load Prompt
# -----------------------------------------------------------------------------
 
# Load the conversation summary agent system prompt from a file
conversation_summary_system_text = load_prompt_yaml(r"config_files\core_engine\conversations_summary_agent_prompts\system_prompt.yaml")
conversation_summary_start_text = load_prompt_yaml(r"config_files\core_engine\conversations_summary_agent_prompts\start_prompt.yaml")
 
# Create chat prompt template
conversation_summary_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", conversation_summary_system_text),
        ("user", conversation_summary_start_text)
    ]
)
 
# -----------------------------------------------------------------------------
# SECTION: LLM - Parser and Chain
# -----------------------------------------------------------------------------
 
class ConversationSummary(BaseModel):
    """
    Pydantic model for the conversation summary response.
 
    Attributes:
        conversation_summary (str): Summarized conversation history
    """
    conversation_summary: str = Field(description="Summarized conversation history")
 
# Create the output parser
parser = JsonOutputParser(pydantic_object=ConversationSummary)
 
# Define the conversation summary agent chain
conversation_summary_chain = conversation_summary_prompt | llm_config_loader() | parser
 
# -----------------------------------------------------------------------------
# SECTION: Conversation Summary Agent Function
# -----------------------------------------------------------------------------
 
def conversation_summary_agent(conversation_history: List[List[Dict[str, str]]]) -> Tuple[str, int, int]:
    """
    Summarizes the entire conversation history if it exceeds a certain length.
 
    This function takes the conversation history and generates a concise summary that captures
    the key points, user queries, and agent responses in a clear and relevant manner.
 
    Args:
        conversation_history (List[List[Dict[str, str]]]): A list of lists, where each sublist
        represents a sequence of conversation exchanges as dictionaries.
 
    Returns:
        Tuple: A tuple containing:
            - str: The summarized conversation history.
            - int: The number of input tokens used by the AI model.
            - int: The number of output tokens generated by the AI model.
 
    Raises:
        ValueError: If the conversation history is not provided in the correct format.
    """
 
    # Validate the input conversation history
    if not isinstance(conversation_history, list) or not all(isinstance(entry, list) and all(isinstance(sub_entry, dict) for sub_entry in entry) for entry in conversation_history):
        raise ValueError("Invalid input: Expected a list of lists of dictionaries representing the conversation history.")
 
    # Flatten the conversation history into a single list of dictionaries
    flattened_history = [item for sublist in conversation_history for item in sublist]
 
    # Use OpenAI callback to capture token counts
    with get_openai_callback() as cb:
        # Invoke the conversation summary chain to generate a summary of the flattened conversation history
        ai_response = conversation_summary_chain.invoke({
            "conversation_history": flattened_history
        })
        input_tokens_count = cb.prompt_tokens
        output_tokens_count = cb.completion_tokens
 
    # Extract the conversation summary from the AI response
    conversation_summary = ai_response['conversation_summary']
 
    # Return the conversation summary along with input and output token counts
    return conversation_summary, input_tokens_count, output_tokens_count
 
# -----------------------------------------------------------------------------
# END OF MODULE
# -----------------------------------------------------------------------------