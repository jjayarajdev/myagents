"""
This module provides a task execution framework for a multi-agent AI system, implementing
a Supervisor-Worker pattern where tasks are dynamically generated, prioritized, and executed
based on user inputs and conversation context.
"""

from typing import Any, Dict, List
import logging
import os

# Local application imports
from agents.generic_conversation_agent import generic_conversation_agent
from workflow_execution.supervisor_agent.dependency_resolver_agent import dependency_resolver
from agents.generic_agent import generic_agent
from workflow_execution.supervisor_agent.supervisor_agent import supervisor_agent

# Third-party imports
from dotenv import load_dotenv

# -----------------------------------------------------------------------------
# SECTION: Logger Setup
# -----------------------------------------------------------------------------

# Get a logger instance for this module
logger = logging.getLogger(__name__)

# -----------------------------------------------------------------------------
# SECTION: Environment Setup
# -----------------------------------------------------------------------------

# Load environment variables from .env file
load_dotenv()


# -----------------------------------------------------------------------------
# SECTION: Task Executor Implementation
# -----------------------------------------------------------------------------

def execute_tasks(ai_tasks_list,total_input_tokens_count,total_output_tokens_count,user)->tuple[list[Any], int, int, list[str]]:
    """
    Executes the list of tasks generated by the supervisor agent, handles dependency resolution,
    and updates task outputs and token counts.
    Args:
        ai_tasks_list (list): List of tasks generated by the supervisor agent.
    Returns:
        tuple: (task_outputs, total_input_tokens_count, total_output_tokens_count, generated_snowflake_queries_list)
    """
    task_outputs = []  # List to store task outputs with sequence IDs


    for i, task in enumerate(ai_tasks_list, start=1):  # Start sequence from 1
        function_name = task.get("function_name","")
        function_params = task["function_params"]
        function_params_ques = task["function_params"].get("user_input", "")
        task_id = i  # Use sequence number as task ID
        # Resolve dependencies if any
        if task.get("depends_on") is not None:
            dependent_task_output = task_outputs[max(int(task["depends_on"]) - 1, 0)]["output"]
            next_task_info = {"function_params": function_params}
            function_params, input_tokens_count, output_tokens_count = dependency_resolver(
                dependent_task_output,
                next_task_info
            )
            total_input_tokens_count += input_tokens_count
            total_output_tokens_count += output_tokens_count
            logger.info("Dependency Resolver Output: %s", function_params)
       # Retrieve the function object from the global namespace
        # Execute the agent function
        scratchpad = None  # Default to None to handle different types of outputs
        if function_name != "" or function_name is not None:  # Simplified check for non-empty function name
            try:
                if function_name == "generic_conversation_agent":
                    agent_outputs = generic_conversation_agent(function_params)
                else:
                    agent_outputs = generic_agent(function_name, function_params, user)
                
                # Unpack the function output (same for both agents)
                scratchpad, input_tokens_count, output_tokens_count = agent_outputs
                total_input_tokens_count += input_tokens_count
                total_output_tokens_count += output_tokens_count
            
            except Exception as e:
                scratchpad = f"Error in {function_name}: {str(e)}"
                logger.error(f"Error executing {function_name}: {e}")
        else:
            scratchpad = f"Function '{function_name}' not found."
            logger.error(f"Function '{function_name}' not found in the global namespace.")
 
        # Only store task output if it is non-empty
        if scratchpad not in (None, "", [], {}, ())  and bool(scratchpad):
            task_outputs.append({
                "task_id": task_id,
                "function_name": function_name,
                "function_params_ques":function_params_ques,
                "output": scratchpad
            })

            print("\n")
            print("#" * 50)
            print(f"Task ID = {task_id}, Agent = {function_name}")
            print("Agent Output = ")
            print(scratchpad)
            print("#" * 50)
            print("\n")

            
 
    return task_outputs, total_input_tokens_count, total_output_tokens_count

#-----------------------------------------------
# SECTION : Supervisor agent logic execution
#-----------------------------------------------

def supervisor_logic_exec(user_input: str, 
    conversation_history: str, 
    user_details: Dict[str, Any],
    total_input_tokens_count: int,
    total_output_tokens_count: int,
    retry_context: List = [],
    user=None
)-> tuple[list[Any], int, int]:
        
    """
    
    Executes a sequence of tasks based on user input, using a supervisor agent.

    This function orchestrates the process of:

    1. **Task Generation:** Uses a `supervisor_agent` to create a list of tasks 
       based on user input, conversation history, user details, and previous 
       retry attempts. The supervisor agent handles task decomposition and 
       potentially incorporates feedback from previous failures.

    2. **Task Execution:** Executes the generated tasks using the `execute_tasks` 
       function.

    3. **Token Counting:** Tracks the total input and output tokens consumed 
       during both task generation and execution.

    Args:
        user_input (str): The user's input string.
        conversation_history (str): The history of the conversation.
        user_details (Dict[str, Any]): A dictionary containing user information 
                                        (e.g., name, country).
        total_input_tokens_count (int):  The running total of input tokens.
        total_output_tokens_count (int): The running total of output tokens.
        retry_context (List): Context from previous failed attempts.

    Returns:
        - tuple[List[Any], int, int]: A tuple containing:
        - task_outputs (List[Any]): The results of executing the tasks.
        - total_input_tokens_count (int): Updated total input token count.
        - total_output_tokens_count (int): Updated total output token count.
    """
    
    # Step 1: Generate tasks using the supervisor agent, including retry context
    ai_tasks_list, input_tokens_count, output_tokens_count = supervisor_agent(
        user_details["user_name"],
        user_details["country"],
        user_details,
        user_input,
        conversation_history,
        retry_context=retry_context , # Pass feedback on what went wrong in previous attempts
        user=user
    )
    total_input_tokens_count += input_tokens_count
    total_output_tokens_count += output_tokens_count

        
    print("Supervisor Agent")
    print(ai_tasks_list)
    print('*' * 50)

    logger.info("Supervisor Agent Output: %s", ai_tasks_list)

    # Step 2: Execute tasks using the execute_tasks function
    task_outputs, input_tokens_count, output_tokens_count = execute_tasks(ai_tasks_list,total_input_tokens_count,total_output_tokens_count,user)
    
    total_input_tokens_count += input_tokens_count
    total_output_tokens_count += output_tokens_count
    
    return task_outputs,total_input_tokens_count,total_output_tokens_count

# -----------------------------------------------------------------------------
# END OF MODULE
# -----------------------------------------------------------------------------